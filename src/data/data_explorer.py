import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

def explore_dataset():
    """Quick and dirty data exploration - let's see what we're working with"""
    print("ðŸ” EXPLORING YOUR DATASETAFRICAMALARIA")
    print("=" * 60)
    
    # Load the data
    try:
        # Try different possible file locations
        if os.path.exists("data/DatasetAfricaMalaria"):
            df = pd.read_csv("data/DatasetAfricaMalaria")
            print("âœ… Loaded: data/DatasetAfricaMalaria")
        elif os.path.exists("data/DatasetAfricaMalaria.csv"):
            df = pd.read_csv("data/DatasetAfricaMalaria.csv")
            print("âœ… Loaded: data/DatasetAfricaMalaria.csv")
        else:
            print("âŒ File not found!")
            return
    except Exception as e:
        print(f"âŒ Error loading file: {e}")
        return
    
    # BASIC DATASET INFO
    print(f"\nðŸ“Š DATASET SHAPE: {df.shape}")
    print(f"ðŸ“‹ COLUMNS: {df.columns.tolist()}")
    
    print(f"\nðŸ“ˆ DATA TYPES:")
    print(df.dtypes)
    
    print(f"\nâ“ MISSING VALUES:")
    missing = df.isnull().sum()
    print(missing[missing > 0])
    
    # BASIC STATISTICS
    print(f"\nðŸ“Š BASIC STATISTICS:")
    print(df.describe())
    
    # FIRST FEW ROWS
    print(f"\nðŸ‘€ FIRST 5 ROWS:")
    print(df.head())
    
    # CHECK FOR MALARIA-RELATED COLUMNS
    malaria_keywords = ['malaria', 'case', 'death', 'incidence', 'prevalence', 'risk', 'fever']
    malaria_columns = [col for col in df.columns if any(keyword in col.lower() for keyword in malaria_keywords)]
    
    print(f"\nðŸŽ¯ MALARIA-RELATED COLUMNS FOUND: {malaria_columns}")
    
    if malaria_columns:
        print(f"\nðŸ“Š MALARIA COLUMNS INFO:")
        for col in malaria_columns:
            print(f"{col}:")
            print(f"  - Unique values: {df[col].nunique()}")
            print(f"  - Sample values: {df[col].unique()[:5]}")
            if df[col].dtype in ['int64', 'float64']:
                print(f"  - Range: {df[col].min()} to {df[col].max()}")
    
    # CHECK FOR GEOGRAPHIC COLUMNS
    geo_columns = [col for col in df.columns if any(keyword in col.lower() for keyword in ['country', 'region', 'district', 'zone', 'area'])]
    print(f"\nðŸŒ GEOGRAPHIC COLUMNS: {geo_columns}")
    
    # CHECK FOR RISK FACTOR COLUMNS
    risk_columns = [col for col in df.columns if any(keyword in col.lower() for keyword in 
                   ['rain', 'temp', 'humid', 'population', 'density', 'poverty', 'health', 'sanitation'])]
    print(f"\nðŸ“ˆ RISK FACTOR COLUMNS: {risk_columns}")
    
    return df

def create_quick_visualizations(df):
    """Create some quick plots to understand the data"""
    print(f"\nðŸ“Š CREATING QUICK VISUALIZATIONS...")
    
    # Set up plotting style
    plt.style.use('default')
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. Check for numeric columns distribution
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    if len(numeric_cols) > 0:
        # Plot first 4 numeric columns
        for i, col in enumerate(numeric_cols[:4]):
            ax = axes[i//2, i%2]
            df[col].hist(ax=ax, bins=20, alpha=0.7)
            ax.set_title(f'Distribution of {col}')
            ax.set_xlabel(col)
            ax.set_ylabel('Frequency')
    
    plt.tight_layout()
    plt.savefig('data_exploration.png', dpi=100, bbox_inches='tight')
    print("âœ… Saved visualization as 'data_exploration.png'")
    
    # 2. Correlation heatmap if we have enough numeric columns
    if len(numeric_cols) > 2:
        plt.figure(figsize=(12, 8))
        correlation_matrix = df[numeric_cols].corr()
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
        plt.title('Correlation Matrix of Numeric Features')
        plt.tight_layout()
        plt.savefig('correlation_matrix.png', dpi=100, bbox_inches='tight')
        print("âœ… Saved correlation matrix as 'correlation_matrix.png'")

def check_data_quality(df):
    """Check data quality issues"""
    print(f"\nðŸ” DATA QUALITY CHECK:")
    
    # Check for duplicates
    duplicates = df.duplicated().sum()
    print(f"ðŸ” Duplicate rows: {duplicates}")
    
    # Check for constant columns
    constant_cols = [col for col in df.columns if df[col].nunique() == 1]
    print(f"ðŸ“ Constant columns: {constant_cols}")
    
    # Check for high cardinality categorical columns
    categorical_cols = df.select_dtypes(include=['object']).columns
    high_cardinality = []
    for col in categorical_cols:
        if df[col].nunique() > 50:
            high_cardinality.append((col, df[col].nunique()))
    
    if high_cardinality:
        print(f"ðŸŽ¯ High cardinality categorical columns: {high_cardinality}")
        
if __name__ == "__main__":
    print("ðŸš€ STARTING DATA EXPLORATION...")
    df = explore_dataset()
    
    if df is not None:
        create_quick_visualizations(df)
        check_data_quality(df)
        
        print(f"\nðŸŽ¯ NEXT STEPS SUGGESTIONS:")
        print("1. Review the output above to understand your data")
        print("2. Check the generated PNG files for visual insights")
        print("3. Identify which column should be your target variable")
        print("4. Decide which features to use for prediction")